{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import artm\n",
    "from artm import hARTM\n",
    "\n",
    "import sys\n",
    "sys.path.append('utils/')\n",
    "# you need sklearn for simple loading\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import glob \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier = hARTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0 = hier.add_level(num_topics=3)\n",
    "level0.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=100, \n",
    "                                      class_id='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_20newsgroups(path='../data'):\n",
    "    \"\"\"\n",
    "    Download train part of 20newsgroups collection. Simple preprocess it, \n",
    "    convert to vowpal wabbit format, save in path/20newsgroups directory.\n",
    "    \n",
    "    This function does nothing if file path/20newsgroups/20newsgroups_train.vw\n",
    "    already exists.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path: str\n",
    "        The folder for the collection saving\n",
    "    \"\"\"\n",
    "    if os.path.isfile('{}/20newsgroups/20newsgroups_train.vw'.format(path)):\n",
    "        return None\n",
    "    data = fetch_20newsgroups(data_home=path, subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "    if os.path.isfile('{}/20newsgroups'.format(path)):\n",
    "        os.remove('{}/20newsgroups'.format(path))\n",
    "    if not os.path.isdir('{}/20newsgroups'.format(path)):\n",
    "        os.mkdir('{}/20newsgroups'.format(path))\n",
    "    with open('{}/20newsgroups/20newsgroups_train.vw'.format(path), 'w') as f_output:\n",
    "        for i, (document, document_class) in enumerate(zip(data['data'], data['target'])):\n",
    "            content = \" \".join(re.sub('[^a-z]', ' ', document.lower()).split())\n",
    "            print(content)\n",
    "            new_line = '{} |text {} |class_id {}\\n'.format(i, content, document_class)\n",
    "            f_output.write(new_line)\n",
    "    os.remove('{}/20news-bydate.pkz'.format(path))\n",
    "    \n",
    "    \n",
    "load_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/lang_data.vw'\n",
    "batches_path = 'data/batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(glob.glob(os.path.join(batches_path + '*.batch'))) < 1:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path=data_path, data_format='vowpal_wabbit',\n",
    "                                            target_folder=batches_path)\n",
    "else:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path=batches_path, data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.Dictionary(name=dictionary, num_entries=29493)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = artm.Dictionary('dictionary')\n",
    "dictionary.gather(batches_path)\n",
    "dictionary.filter(min_df=100, max_tf=17390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7f32f78943b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mr9bit/bigartm/env/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\", line 228, in __iter__\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-391055e1fa3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlevel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlevel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_offline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_collection_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bigartm/env/lib/python3.6/site-packages/artm/artm_model.py\u001b[0m in \u001b[0;36mfit_offline\u001b[0;34m(self, batch_vectorizer, num_collection_passes, reset_nwt)\u001b[0m\n\u001b[1;32m    578\u001b[0m                     self._pool.apply_async(func=self.master.fit_offline,\n\u001b[1;32m    579\u001b[0m                                            args=(batch_vectorizer.batches_ids,\n\u001b[0;32m--> 580\u001b[0;31m                                                  batch_vectorizer.weights, 1, None, reset_nwt)),\n\u001b[0m\u001b[1;32m    581\u001b[0m                     batch_vectorizer.num_batches)\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bigartm/env/lib/python3.6/site-packages/artm/artm_model.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bigartm/env/lib/python3.6/site-packages/artm/master_component.py\u001b[0m in \u001b[0;36mfit_offline\u001b[0;34m(self, batch_filenames, batch_weights, num_collection_passes, batches_folder, reset_nwt)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtmFitOfflineMasterModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     def fit_online(self, batch_filenames=None, batch_weights=None, update_after=None,\n",
      "\u001b[0;32m~/bigartm/env/lib/python3.6/site-packages/artm/wrapper/api.py\u001b[0m in \u001b[0;36martm_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "level0.initialize(dictionary=dictionary)\n",
    "level0.fit_offline(batch_vectorizer, num_collection_passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: \n",
      "\"asoc, *mtd,, -1}, -1},, ##, 7,, loff_t, partition, shift,, nbits,, vreg,, tps6586x_regulator, ebit0,, ereg1,, ereg0,, soc_tplg, usb_mixer_elem_info, 32,, dev_err(tplg->dev,, errcode_t, unitid,, mtd, 7),, bb,, (!, _pname,, ene,, (ret, len), bits, ebit1,, 25000,, tps6586x_ldo0,, tps6586x_ldo,, from,, blk), *tplg,, mixer, pass, part->offset,, regulator, kcontrol, sndrv_ctl_elem_id_name_maxlen), p4_escr_emask_bit(p4_event_bsq_cache_reference,, min_uv,, supplyv2,, n_volt,, uv_step,, \"vinldo678\",, --\n",
      "topic_1: \n",
      "\"\"\", inode, kctx);, js,, kctx,, extern, contexts, dentry, cores, ssize_t, none, kbasep_js_kctx_info, because, mali_false), ***, release, scheduled, queue, name, path, ;, affinity, following, (0x0000), error;, does, lock, msm_vidc_core, also, time, flags;, flags, call, kbase_debug_assert(kctx, kbase_debug_print_info(kbase_jm,, x, object, ctx, slot, printf, enum, (u32), change, core, *,, std, spin_unlock_irqrestore(&js_devdata->runpool_irq.lock,, returns, irq, might\n",
      "topic_2: \n",
      "rtl818x_iowrite8(priv,, (mem->validation_bits, usb_descriptor_header, nxwr32(adapter,, net_device, sack, kernel, .flags, printk(kern_err, (retval, (proc->validation_bits, scnprintf(msg, bundle, sctp_association, sctp_xmit_ok), *chunk), pr_err(\"%s, *adapter), ieee80211_hw, ip, multiple, (x, dotdot%p\\n\",, *asoc, bundling, *chunk,, dotdot%p, rtl8180_priv, key, printk(kern_info, 8), dev->priv;, timer, f_acm, -eio;, skb, 0x%016llx\\n\",, ring, *priv, checksum, support, __u16, firmware, rtl818x_iowrite32(priv,, rule, tmp, pte, msm_routing_put_audio_mixer),, msm_routing_get_audio_mixer,, __le32\n"
     ]
    }
   ],
   "source": [
    "for topic_name in level0.topic_names:\n",
    "    print (topic_name + ': ')\n",
    "    print (\", \".join(level0.score_tracker['TopTokensScore'].last_tokens[topic_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1 = hier.add_level(num_topics=25, topic_names=['child_topic_' + str(i) for i in range(25)], \n",
    "                        parent_level_weight=1)\n",
    "level1.regularizers.add(artm.HierarchySparsingThetaRegularizer(name=\"HierSp\", tau=1.0))\n",
    "level1.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=120, \n",
    "                                      class_id='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1.initialize(dictionary=dictionary)\n",
    "level1.fit_offline(batch_vectorizer, num_collection_passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(level0.get_psi()), len(level1.get_psi())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = level1.get_psi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Psi support:\", psi.values.max(axis=1).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_threshold = 0.01\n",
    "parent_counts = np.zeros(0)\n",
    "for level_idx in range(1, hier.num_levels):\n",
    "    psi = hier.get_level(level_idx).get_psi().values\n",
    "    parent_counts = np.hstack((parent_counts, (psi > psi_threshold).sum(axis=1)))\n",
    "print (\"Mean parents count:\", parent_counts.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(psi) * Ntw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = artm.messages.Batch()\n",
    "batch_name = 'phi1.batch'\n",
    "\n",
    "with open(batch_name, \"rb\") as f:\n",
    "    batch.ParseFromString(f.read())\n",
    "    \n",
    "Ntw = np.zeros(len(level0.topic_names))\n",
    "    \n",
    "for i,item in enumerate(batch.item):\n",
    "    for (token_id, token_weight) in zip(item.field[0].token_id, item.field[0].token_weight):\n",
    "        Ntw[i] += token_weight\n",
    "\n",
    "Nt1t0 = np.array(psi) * Ntw\n",
    "psi_bayes = (Nt1t0 / Nt1t0.sum(axis=1)[:, np.newaxis]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_child = np.argmax(psi_bayes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_parent_name = 'topic_4'\n",
    "print(topic_parent_name + ':')\n",
    "print(\" \".join(level0.score_tracker['TopTokensScore'].last_tokens[topic_parent_name]))\n",
    "print('')\n",
    "i=9\n",
    "for child in np.where(indexes_child == i)[0]:\n",
    "    print('    ' + level1.topic_names[child] + ': ')\n",
    "    print(\" \".join(level1.score_tracker['TopTokensScore'].last_tokens[level1.topic_names[child]]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi1 = level1.get_psi()\n",
    "psi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokens0 = level0.score_tracker[\"TopTokensScore\"].last_tokens\n",
    "tokens1 = level1.score_tracker[\"TopTokensScore\"].last_tokens\n",
    "for t, topic_name in enumerate(level0.topic_names):\n",
    "    print (topic_name + ': ')\n",
    "    for word in tokens0[topic_name]:\n",
    "        print (word, end=' ')\n",
    "    print()\n",
    "    for s, topic_name1 in enumerate(level1.topic_names):\n",
    "        if psi1[topic_name ][ topic_name1 ] > 0.05:\n",
    "            print (\"\\t\", topic_name1 + ': ')\n",
    "            for word in tokens1[topic_name1]:    \n",
    "                print (word, end=' ')\n",
    "            print()\n",
    "    print(\"==\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi1[\"topic_0\"][\"child_topic_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "z\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(1,1, figsize=(11,20))\n",
    "heatplot = ax.imshow(psi1, cmap='hot')\n",
    "ax.set_xticklabels(['child_topic_' + str(i) for i in range(25)], rotation=40)\n",
    "ax.set_yticklabels(['topic_' + str(i) for i in range(25)])\n",
    "\n",
    "tick_spacing = 1\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
